{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootURL = 'https://www.mycareersfuture.sg'\n",
    "#mainURL = 'https://www.mycareersfuture.sg/search?sortBy=new_posting_date&page=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go the specific page and retrieve the number of jobs\n",
    "initialURL = 'https://www.mycareersfuture.sg/search?sortBy=new_posting_date&page=0'\n",
    "\n",
    "# call up the Chrome webdriver\n",
    "driver = webdriver.Chrome(executable_path = 'C:/Users/nchandra.CATLIN/chromedriver')\n",
    "driver.get(initialURL)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "firstsoup = bs(html, 'lxml')\n",
    "    \n",
    "time.sleep(1)\n",
    "    \n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20,260 jobs found'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobcount = firstsoup.find('span', {'id':'search-results-message'}).find('div').find(text = True, recursive = False)\n",
    "jobcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagecount = round(int(jobcount.split()[0].replace(',',''))/20)\n",
    "pagecount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the pages and return the fields specified\n",
    "records = []\n",
    "for pcount in range(pagecount):\n",
    "#for pcount in range(1,10):\n",
    "    \n",
    "    # Go the specific page\n",
    "    searchURL = 'https://www.mycareersfuture.sg/search?sortBy=new_posting_date&page='+str(pcount)\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path = 'C:/Users/nchandra.CATLIN/chromedriver')\n",
    "    driver.get(searchURL)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = bs(html, 'lxml')\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    for x in range(20):\n",
    "        company = ''\n",
    "        jobtitle = ''\n",
    "        location = ''\n",
    "        jobtype = ''\n",
    "        seniority = ''\n",
    "        industry = ''\n",
    "        salary = ''\n",
    "        govtscheme = ''\n",
    "        skill_list = ''\n",
    "        jd_list = ''\n",
    "        jr_list = ''\n",
    "        \n",
    "        cardno = 'job-card-' + str(x)\n",
    "        \n",
    "        #link.append(soup.find('div', {'id':cardno}).find('div', {'class':'card relative'}).find('a')['href'])\n",
    "        \n",
    "        # Create job detail link\n",
    "        try:\n",
    "            sublink = soup.find('div', {'id':cardno}).find('div', {'class':'card relative'}).find('a')['href']\n",
    "        except AttributeError:\n",
    "            print('cannot find next link')\n",
    "            continue\n",
    "        else:\n",
    "            jobdetaillink = rootURL + sublink\n",
    "            \n",
    "        ## Open job detail page\n",
    "        driver = webdriver.Chrome(executable_path = 'C:/Users/nchandra.CATLIN/chromedriver')\n",
    "        driver.get(jobdetaillink)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        jobdetailpage_html = driver.page_source\n",
    "        jobdetailsoup = bs(jobdetailpage_html, 'lxml')\n",
    "    \n",
    "        time.sleep (5)\n",
    "        \n",
    "        driver.close()\n",
    "    \n",
    "        # Company name\n",
    "        co = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('p', {'name':'company'} )\n",
    "        \n",
    "        if co is not None:\n",
    "            company= co.getText().strip()\n",
    "            \n",
    "        else:\n",
    "            company = ''\n",
    "        \n",
    "        #Job Title\n",
    "        jobt = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('h1', {'name':'job_title'})\n",
    "        \n",
    "        if jobt is not None:\n",
    "            jobtitle = jobt.getText().strip()\n",
    "        else:\n",
    "            jobtitle = ''\n",
    "    \n",
    "    \n",
    "        # Location\n",
    "        loc = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('section', {'name' : 'job_info'}).find('p', {'name':'location'})\n",
    "    \n",
    "        if loc is not None:\n",
    "            location = loc.text.strip()\n",
    "        else:\n",
    "            location = ''\n",
    "      \n",
    "    \n",
    "    # Job Type\n",
    "        job = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('p', {'name':'employment_type'})\n",
    "    \n",
    "        if job is not None:\n",
    "            jobtype = job.getText().strip()\n",
    "\n",
    "        else:\n",
    "            jobtype = ''\n",
    "    \n",
    "    # Seniority\n",
    "        snr = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('p', {'name':'seniority'})\n",
    "    \n",
    "        if snr is not None:\n",
    "            seniority = snr.getText().strip()\n",
    "        else:\n",
    "            seniority = ''\n",
    "        \n",
    "    # Industry\n",
    "        ind = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('p', {'name':'category'})\n",
    "        \n",
    "        if ind is not None:\n",
    "            industry = ind.getText().strip()\n",
    "        else:\n",
    "            industry = ''\n",
    "       \n",
    "    # Salary\n",
    "        sal = soup.find('div', {'id': cardno}).find('div', {'class':'card relative'}).find('a').find('span', {'class':'salary_range'})\n",
    "        \n",
    "        if sal is not None:\n",
    "            salary = sal.text.strip()\n",
    "        else:\n",
    "            salary = ''\n",
    "\n",
    "    \n",
    "    # Government Support\n",
    "        gscheme = soup.find('div', {'id':cardno}).find('div', {'class':'card relative'}).find('a').find('p', {'name':'schemes_available'})\n",
    "        \n",
    "        if gscheme is not None:\n",
    "            govtscheme = gscheme.text.strip()\n",
    "            \n",
    "        else:\n",
    "            govtscheme = ''\n",
    "    \n",
    "        \n",
    "    ## Get skill\n",
    "        skill_cont = []\n",
    "        \n",
    "        \n",
    "        skill_finder = jobdetailsoup.find('div',{'class': 'multi-pill-button'})\n",
    "        \n",
    "        if skill_finder is not None:\n",
    "             for skill in skill_finder.find_all('label'):\n",
    "                skill_cont.append(skill.text.strip())           \n",
    "\n",
    "        else:\n",
    "            skill_cont.append('')\n",
    "\n",
    "        skill_list = skill_cont\n",
    "        \n",
    "    ## Get job description\n",
    "        jd_cont = []\n",
    "        \n",
    "        jd_finder = jobdetailsoup.find('div', {'id':'job_description'})\n",
    "        \n",
    "        if jd_finder is not None:\n",
    "            for jd in jd_finder.find_all(['li', 'p']):\n",
    "                jd_cont.append(jd.text.strip())             \n",
    "            \n",
    "        else:\n",
    "            jd_cont.append('')\n",
    "        \n",
    "        jd_list = jd_cont\n",
    "        \n",
    "    ## Get job requirement\n",
    "        jr_cont = []\n",
    "        \n",
    "        jr_finder = jobdetailsoup.find('div', {'id':'requirements'})\n",
    "        \n",
    "        try:\n",
    "            for jr in jr_finder.find_all(['li', 'p']):\n",
    "                jr_cont.append(jr.text.strip())\n",
    "        except:\n",
    "            jr_cont.append('')\n",
    "        jr_list = jr_cont\n",
    "        \n",
    "        records.append([company, jobtitle, location, jobtype, seniority, industry, salary, govtscheme, skill_list, jd_list, jr_list])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to CSV\n",
    "with open(\"C:/Users/nchandra.CATLIN/Desktop/output.csv\", \"a\", encoding='utf-8-sig') as f:\n",
    "    writer = csv.writer(f, lineterminator = '\\n')\n",
    "\n",
    "    for item in records:\n",
    "        writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a dataframe out of the scraped data\n",
    "\n",
    "#df = pd.DataFrame(\n",
    "    #{'Company': company,\n",
    "    #'Job_Title':jobtitle,\n",
    "     #'Location': location,\n",
    "     #'Seniority': seniority,\n",
    "     #'Industry': industry,\n",
    "     #'Salary': salary,\n",
    "     #'Govt_Scheme': govtscheme,\n",
    "     #'Skills':skill_list,\n",
    "     #'Job_Desc': jd_list,\n",
    "     #'Job_Req':jr_list\n",
    "    #}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[13:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
